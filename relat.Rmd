---
title: "O GRANDE TÍTULO"
author: "Alisson Rosa e Vítor Pereira"
abstract: "One Piece > Naruto"
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
geometry: left=1.7cm, right=1.7cm, top=2.5cm, bottom=2.2cm
output:
  bookdown::pdf_document2:
editor_options:
  chunk_output_type: console
indent: true
bibliography: bib.bib 
csl: statistics.csl
nocite: '@*'
link-citations: true
always_allow_html: true


---



```{r setup,include=F}

options(digits = 3) # Arrendodamento
ggplot2::theme_set(ggplot2::theme_minimal()) # Tema dos gráficos produzidos no ggplot2
knitr::opts_chunk$set(echo = F, message = F, warning = F, fig.pos = "H", fig.align = "center", fig.width = 7.8, fig.height = 3.7)
# devtools::install_github("https://github.com/AlissonRP/mypdf1") remova o `#`

library(tidyverse)
library(tidymodels)
library(modeltime)
library(forecast)
```

```{r functions}
barplot <- function(df, v) {
  ggplot(df, aes(
    x = {{ v }},
    y = prop.table(stat(count)),
    fill = {{ v }},
    label = scales::percent(prop.table(stat(count)))
  )) +
    geom_bar(position = "dodge", color = "black") +
    geom_text(
      stat = "count",
      position = position_dodge(.9),
      vjust = -0.5,
      size = 3.5
    ) +
    scale_y_continuous(labels = scales::percent) +
    labs(y = "Proporção", x = df %>%
      select({{ v }}) %>%
      names(), caption = "Fonte: Elaborado pelos autores") +
    theme(plot.title = element_text(hjust = 0.5, size = 10), legend.position = "none")
}

scale_fill_alisson <- function(...) {
  ggplot2:::manual_scale(
    "fill",
    values = setNames(
      c("#EA2129", "#CF6520", "#1EAB78"), levels(as.factor(df$Tipo)),
      ...
    )
  )
}

calcSSE <- function(data, regressor, time, x) {
  loessMod <- try(loess(eval(parse(text = paste(regressor, "~", paste("as.numeric(", time, ")", sep = ""), sep = " "))), data = data, span = x), silent = T)
  res <- try(loessMod$residuals, silent = T)
  if (class(res) != "try-error") {
    sse <- sum(res^2)
  } else {
    sse <- 99999
  }
  return(sse)
}

scale_fill_discrete <- \(...) scale_fill_alisson(...)
```

# Introdução
Naruto é uma animação japonesa (anime)  que adapta a  série de mangá escrita e ilustrada por Masashi Kishimoto, que conta a história de Naruto Uzumaki, um jovem ninja que constantemente procura por reconhecimento e sonha em se tornar Hokage, o ninja líder de sua vila.  
A história é dividida em duas partes, a primeira parte se passa nos anos da pré-adolescência de Naruto (clássico), e a segunda parte se passa em sua adolescência (Shippuden). Nesse trabalho trataremos sobre o Naruto Shippuden, desenvolvendo-o em uma perpestiva de séries temporais, vamos adotar como variável de interesse  a avaliação dos episódios, assim veremos  pontos importantes da saga ao longo do tempo.   
O Banco de dados utilizado é totalmente original, foi criado fazendo *Web scraping* de dois sites diferentes, para aqueles interessados o banco foi dispobilizado [aqui](https://www.kaggle.com/alisson987/naruto-shippuden-rate).


# Informações
```{r }
df <- read_csv("naruto.csv")
```
Como o anime é uma adaptação, existem  episódios fiéis ao mangá (Manga Canon) e episódios  originais do próprio anime, em outras palavras não seguem o material original, esses episódios são chamados de Fillers, existem também episódios que seguem a trama do mangá mas além disso possuem elementos novos, esses chamados de Mixed Canon.  
Vejamos pelo gráfico a seguir a porcentagem do tipo dos episódios

```{r plttipo}
barplot(df, Tipo)
```
É um fato bastante curioso, Naruto Shippuden possui uma quantidade altíssima de episódios fillers, aproximadamente 41%, note pela tabela  que são somente 31 episódios a mais canônicos.
```{r}
df %>%
  group_by(Tipo) %>%
  count() %>%
  rename(Quantidade = n) %>%
  mypdf1::pdf1_tbl("Valores Absolutos do Tipo de Episódio")
```

Em termos de avaliação ao longo do tempo, podemos utilizar como indíce ordinal o próprio número do episódio já que que é uma função injetora no tempo.

```{r}
df %>%
  ggplot(aes(x = numero_episodio, y = rate)) +
  geom_line() +
  gghighlight::gghighlight(200 < numero_episodio & numero_episodio < 400,
    unhighlighted_params = list(colour = "#CB6007")
  ) +
  labs(x = "Numero do episódio", y = "Avaliação")
```
Há bastante coisa a se notar nesse gráfico, primeiramente pelos episódios 200 e 400, existe um indício de alteração na média das variáveis aleatórias, portanto furando o pressuposto de média constante ao longo do tempo, perto dos episódios finais da saga nota-se  também inúmeras quedas bruscas na avaliação sem um contra-peso de avaliações com notas altas, outro indicio de não estacionariedade.  
É importante tentarmos entender um pouco sobre esses episódios com notas baixas, assim vamos ver esse gráfico pelo tipo de episódio.

```{r}
df %>%
  ggplot(aes(x = numero_episodio, y = rate, color = Tipo, group = 1)) +
  geom_line() +
  labs(x = "Numero do episódio", y = "Avaliação") +
  ggplot2::scale_color_manual(breaks = c(levels(as.factor(df$Tipo))), values = c("#EA2129", "#E08223", "#1CD0AD"))
```
Assim fica fácil ver que os episódios com menor avaliação são em sua maior parte fillers, toda queda brusca de avaliação tem um episódio filler envolvido.

É necessário também avaliar a correlação nas avaliações:
```{r}
## esse pacote aqui tem problemas, forecast::ggAcf(df$rate) não funciona, sou obrigado a dar library

ggAcf(df$rate, lag.max = 35, type = c("correlation")) +
  labs(title = "Função de autocorrelação")
```
Uma abordagem importante também é decompor a série temporal, apriori supõe-se a existência de três elementos, a saber: Tendência, sazonalidade e resíduo. Todos esses serão explorados cuidadosamente nas seções posteriores, assim vamos decompor a série para ter um vislumbre de tais elementos:

```{r}
decompose <- forecast::mstl(df$rate)
decompose |> autoplot()
```
```{r}
# normal K
data.frame(decompose)$Remainder |>
  shapiro.test()
```



# Testes
Os gráficos de seção anterior evidenciaram a possibilidade da série não ser estacionária, assim faz-se necessário verificar se  vale de fato para o processo estocástico, com isso  vamos precisar aplicar testes de hipóteses para averiguar  algumas propriedades, como existência de tendência e  sazonalidade.

### Tendência 

Tendência refere-se a um algum  comportamento   não - estocástico da série em algum momento do tempo, se tal comportamento só acontece em alguns momentos especifícos do tempo, chamamos de tendência estocástica, do contrário é dita determistica. Vamos começar pelos testes de tendência deterministica, que em termos sumarizados possuem como hipótese:
$$
H_0:\text{A série possui tendência determistica}
$$
```{r}
kendal <- trend::mk.test(df$rate)
wald <- trend::ww.test(df$rate)
stuart <- trend::cs.test(df$rate)
tab1 <- as.data.frame(c("Cox-Stuart", "Wald-Wolfowitz", "Mann-Kendall"))
tab1[, 2] <- c(stuart$p.value, wald$p.value, kendal$p.value)
names(tab1) <- c("Testes", "P-valor")
tab1$`P-valor` <- round(tab1$`P-valor`, 4)
tab1$`P-valor` <- ifelse(tab1$`P-valor` < 0.05, ifelse(tab1$`P-valor` < 0.0001, "<0,0001*", paste0(as.character(tab1$`P-valor`), "*")), tab1$`P-valor`)
```

```{r}
tab1 %>%
  mypdf1::pdf1_tbl("Testes de Tendência Deterministica")
```

Conforme mostrado pela Tabela anterior podemos ver que pelos testes de 
Cox-Stuart, Wald-Wolfowitz, Mann-Kendall, com índice de significância de 5%, temos que todos os p-valores são menores que 0.05, então concluímos que existe tendência determinística na série temporal. 


### Sazonalidade
Sazonalidade acontece quando a série possui um comportamento que se repete frequencialmente, vamos nessa subseção testar se existe sazonalidade nas avaliação dos episódios, assim temos como hipótese:
$$
H_0:\text{A série possui sazonalidaade}
$$
Os testes aplicados  foram 
Kruskal-Wallis, Friedman e Autocorrelação em lags Sazonais, assim gerando a seguite tabela:

```{r}
krusk <- seastests::kw(df$rate, freq = 7)
friedman <- seastests::fried(df$rate, freq = 7)
tqs <- seastests::qs(df$rate, freq = 7)
tab2 <- as.data.frame(c("Kruskal-Wallis", "Friedman", "Autocorrelação em lags Sazonais"))
tab2[, 2] <- c(krusk$Pval, friedman$Pval, tqs$Pval)
names(tab2) <- c("Testes", "P-valor")
tab2$`P-valor` <- round(tab2$`P-valor`, 4)
tab2$`P-valor` <- ifelse(tab2$`P-valor` < 0.05, ifelse(tab2$`P-valor` < 0.0001, "<0,0001*", paste0(as.character(tab2$`P-valor`), "*")), tab2$`P-valor`)
```

```{r}
tab2 %>%
  mypdf1::pdf1_tbl("Testes de Sazonalidade")
```

Assim podemos ver que pelos testes aplicados com índice de significância de 5%,  concluímos que não existe sazonalidade. 

### Testes de Raiz unitária
Para começar tal seção, primeiros vamos definir um passeio aleatório em sua forma simplificada:
$$
Y_t=Y_{t-1}+\epsilon_t
$$
Onde t refere-se aos indíces de ordenação, e $\epsilon$  um termo aleatório, para facilidade vamos assumir que $E(\epsilon_t)=\mu$ e $var(\epsilon_t)=\sigma^2$ $\forall t$, assim subtraindo-se $Y_{t-1}$ em ambos os lados tem-se $$Y_t-Y_{t-1}=\epsilon_t$$ que é um processo estacionário, o processo anterior é dito processo estacionário em diferença, em outros casos também chamado de processo integrado. O exemplo anterior trata-se de um caso mais geral $$Y_t=\phi Y_{t-1}+\epsilon_t$$ onde evidentemente $\phi=1$, é fácil mostrar que se $|\phi|<1$ tem-se um processo estocástico, aqui portanto, estamos interessados nesse caso, para isso utilizaremos  testes de hipótese. 

Fala-se também que o caso anterior na forma simplificada possui raiz unitária, por causa do operador Lag, aqui não definido, porém  pode-se ler sobre em @morettin2018analise

```{r}
kpss <- tseries::kpss.test(df$rate, null = c("Level", "Trend"), lshort = TRUE)
adf <- tseries::adf.test(df$rate)
pp <- tseries::pp.test(df$rate)
tab3 <- as.data.frame(c("Kwiatkowski-Phillips-Schmidt-Shin (KPSS)", "Augmented Dickey-Fuller (ADF)", "Phillips-Perron (PP)"))
tab3[, 2] <- c(kpss$p.value, adf$p.value, pp$p.value)
names(tab3) <- c("Testes", "P-valor")
tab3$`P-valor` <- round(tab3$`P-valor`, 4)
tab3$`P-valor` <- ifelse(tab3$`P-valor` < 0.05, ifelse(tab3$`P-valor` < 0.0001, "<0,0001*", paste0(as.character(tab3$`P-valor`), "*")), tab3$`P-valor`)
```

```{r}
tab3 %>%
  mypdf1::pdf1_tbl("Testes de Tendência Estocástica")
```

Conforme mostrado pela Tabela anterior podemos ver que pelos testes de 
Dickey-Fuller Aumentado, Phillips-Perron, KPSS, com índice de significância de 5%, temos que os p-valores dos testes ADF e PP são menores que 0.05 e do teste KPSS é maior que 0.05, então concluímos que não existe tendência estocástica na série temporal. Pois, nos testes ADF e PP, a hipótese nula é a existência de raiz unitária e no teste de KPSS, a hipótese nula é não existência de raiz unitária.


# Modelagem

```{r }
t <- df %>%
  ggplot(aes(numero_episodio, rate)) +
  geom_line(size = 0.8, color = "#050A03") +
  theme_void() +
  labs("Série")
t %>%
  ggimage::ggbackground(background = "https://www.ixpap.com/images/2021/03/desktop-naruto-wallpaper-ixpap.jpg")
```


```{r }
df %>%
  group_by(Saga) %>%
  summarise(mean = mean(rate)) %>%
  arrange(desc(mean))
```

## Médias Móveis Simples

```{r}
mms <- TTR::SMA(df$rate, n = 21)
df1 <- cbind(df, mms)
df1 %>%
  ggplot(aes(x = numero_episodio)) +
  geom_line(aes(y = rate, colour = "SerieNormal")) +
  geom_line(aes(y = mms, colour = "MediaMovel")) +
  labs(x = "Numero do episódio", y = "Avaliação") +
  scale_colour_manual("",
    breaks = c("SerieNormal", "MediaMovel"),
    values = c(
      "SerieNormal" = "#1EAB78",
      "MediaMovel" = "#CF6520"
    )
  )
```

## Média Móvel Simples com Previsão
Utilizando o pacote smooth.

```{r}
mms1 <- smooth::sma(df$rate[1:400], order=21,silent=FALSE, interval= 'p', h=100)
fit_forecast<- data.frame(forecast= c(mms1$fitted,mms1$forecast), n = 1:length(c(mms1$fitted,mms1$forecast)))
fit_forecast<- fit_forecast %>%
  mutate(Dados = case_when(
    n == 1:length(mms1$fitted) ~ "Predição",
    n == (length(mms1$fitted)+1):length(c(mms1$fitted,mms1$forecast)) ~ "Previsão"))
ICbands <- data.frame(upper=mms1$upper, lower=mms1$lower, n=(length(mms1$fitted)+1):(length(mms1$fitted) +length(mms1$forecast)))
p <- ggplot()
p <- p + geom_ribbon(data=ICbands, aes(x=n,ymin=lower, ymax=upper), fill = 'grey70')
p <- p + geom_line(data = df1, aes(x= numero_episodio,y = rate, colour = "SerieNormal")) 
p <- p + geom_line(data=fit_forecast,aes(x=n,y = forecast, colour = "Forecast"))
p <- p + geom_vline(xintercept=max(df1$numero_episodio))
p

```


## Regressão LOESS

```{r results = F}
op1 <- optim(par = c(0.5), fn = calcSSE, method = "SANN", data = df1, regressor = "rate", time = "Time")
rl1 <- loess(rate ~ as.numeric(Time), data = df1, span = op1$par)
###predict(rl1,seq(as.Date("2017-03-23"), length = 5, by = 'week'))
prl <- predict(rl1, as.numeric(df1$Time), se = T)
df1 <- cbind(df, prl$fit)
df1 %>%
  ggplot(aes(x = numero_episodio)) +
  geom_line(aes(y = rate, colour = "SerieNormal")) +
  geom_line(aes(y = `prl$fit`, colour = "RegLoess")) +
  geom_ribbon(aes(ymin=prl$fit-prl$se.fit, ymax=prl$fit+prl$se.fit, alpha = 0.05)) +
  labs(x = "Numero do episódio", y = "Avaliação") +
  scale_colour_manual("",
    breaks = c("SerieNormal", "RegLoess"),
    values = c(
      "SerieNormal" = "#1EAB78",
      "RegLoess" = "#CF6520"
    )
  )
```

## Suavização Exponencial
### Sem Amortecimento

```{rresults = F}
splits <- initial_time_split(df, prop=0.8)
model <- exp_smoothing() %>%
    set_engine("ets")
model_fit <- model %>%
  fit(log(rate) ~ as.Date(Time), data = training(splits))
model_fit
model2 <- exp_smoothing(error = "multiplicative",trend = "additive",season = "multiplicative")  %>%
    set_engine("ets")
model_fit2 <- model2 %>%
  fit(log(rate) ~ as.Date(Time), data = training(splits))
model_fit2
model_fit3 <- model %>%
  fit(rate ~ as.Date(Time), data = training(splits))
model_fit3
model3 <- exp_smoothing() %>%
    set_engine("croston")
model_fit4 <- model3 %>%
  fit(log(rate) ~ as.Date(Time), data = training(splits))
model_fit4
model_fit5 <- model3 %>%
  fit(rate ~ as.Date(Time), data = training(splits))

models <- modeltime_table(model_fit, model_fit2, model_fit3, model_fit4, model_fit5)
predict_models <- models %>%
    modeltime_calibrate(new_data = testing(splits))
predict_models %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = df
    ) %>%
    plot_modeltime_forecast(
    )
predict_models %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy()
```

```{r}
dfts = msts(df %>% select(rate, numero_episodio),seasonal.periods = 365/7, start=c(2007,2.5))
treino <- df[1:400,]
treino <- window(dfts[,1], end=c(2014,38))
teste <- window(dfts[,1], start=c(2014,38))

h1 <- holt(treino, h = 100)
h2 <- holt(treino, damped=TRUE, h = 100)

#hw(treino[350:400],seasonal="multiplicative", h = 10) #Não consegui utilizar voltou o erro de frequência
#h1$model$
```


```{r}
forecast_h1 <- data.frame(forecast= c(h1$fitted,h1$mean), n = 1:length(c(h1$fitted,h1$mean)))
ICbands_h1 <- data.frame(upper=h1$upper[,2], lower=h1$lower[,2], n=(length(h1$fitted)+1):(length(h1$fitted) +length(h1$mean)))
forecast_h1<- forecast_h1 %>%
  mutate(Dados = case_when(
    n == 1:length(h1$fitted) ~ "Predição",
    n == (length(h1$fitted)+1):length(c(h1$fitted,h1$mean)) ~ "Previsão"))
p <- ggplot()
p <- p + geom_ribbon(data=ICbands_h1, aes(x=n,ymin=lower, ymax=upper), fill = 'grey70')
p <- p + geom_line(data = df1, aes(x= numero_episodio,y = rate, colour = "SerieNormal")) 
p <- p + geom_line(data=forecast_h1,aes(x=n,y = forecast, colour = "Forecast"))
p <- p + geom_vline(xintercept=max(df1$numero_episodio))
p
```


### Com Amortecimento

```{r}
forecast_h2 <- data.frame(forecast= c(h2$fitted,h2$mean), n = 1:length(c(h2$fitted,h2$mean)))
ICbands_h2 <- data.frame(upper=h2$upper[,2], lower=h2$lower[,2], n=(length(h2$fitted)+1):(length(h2$fitted) +length(h2$mean)))
forecast_h2<- forecast_h2 %>%
  mutate(Dados = case_when(
    n == 1:length(h2$fitted) ~ "Predição",
    n == (length(h2$fitted)+1):length(c(h2$fitted,h2$mean)) ~ "Previsão"))
p <- ggplot()
p <- p + geom_ribbon(data=ICbands_h2, aes(x=n,ymin=lower, ymax=upper), fill = 'grey70')
p <- p + geom_line(data = df1, aes(x= numero_episodio,y = rate, colour = "SerieNormal")) 
p <- p + geom_line(data=forecast_h2,aes(x=n,y = forecast, colour = "Forecast"))
p <- p + geom_vline(xintercept=max(df1$numero_episodio))
p
```

## Calculando Métricas de Acurácia dos Modelos não-ModelTime

```{r}
mae = mape = mase = smape = rmse = is.vector(NULL)
  true_values1 = df %>% filter(numero_episodio > max(numero_episodio) - nrow(fit_forecast %>% filter(Dados == "Previsão"))) %>% select(rate)
true_values2 = df %>% filter(numero_episodio > max(numero_episodio - nrow(forecast_h2 %>% filter(Dados == "Previsão")))) %>% select(rate)
v1 = fit_forecast %>% filter(Dados == "Previsão") %>% select(forecast)
v2 = forecast_h1 %>% filter(Dados == "Previsão") %>% select(forecast)
v3 = forecast_h2 %>% filter(Dados == "Previsão") %>% select(forecast)
mae[1] = DescTools::MAE(v1$forecast,true_values1$rate)
mae[2] = DescTools::MAE(v2$forecast,true_values2$rate)
mae[3] = DescTools::MAE(v3$forecast,true_values2$rate)
mape[1] = DescTools::MAPE(v1$forecast,true_values1$rate)
mape[2] = DescTools::MAPE(v2$forecast,true_values2$rate)
mape[3] = DescTools::MAPE(v3$forecast,true_values2$rate)
smape[1] = DescTools::SMAPE(v1$forecast,true_values1$rate)
smape[2] = DescTools::SMAPE(v2$forecast,true_values2$rate)
smape[3] = DescTools::SMAPE(v3$forecast,true_values2$rate)
rmse[1] = DescTools::RMSE(v1$forecast,true_values1$rate)
rmse[2] = DescTools::RMSE(v2$forecast,true_values2$rate)
rmse[3] = DescTools::RMSE(v3$forecast,true_values2$rate)
```
```{r}
cbind(c("SMA", "Holt", "Holt amortecido"),mae,mape,smape, rmse) %>%
    mypdf1::pdf1_tbl("Métricas nos dados de teste")
```


# Referências
