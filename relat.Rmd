---
title: "O GRANDE TÍTULO"
author: "Alisson Rosa e Vítor Pereira"
abstract: "One Piece > Naruto"
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
geometry: left=1.7cm, right=1.7cm, top=2.5cm, bottom=2.2cm
output:
  bookdown::pdf_document2:
editor_options:
  chunk_output_type: console
indent: true
bibliography: bib.bib 
csl: statistics.csl
nocite: '@*'
link-citations: true
always_allow_html: true
---



```{r setup,include=F}

options(digits = 3) # Arrendodamento
ggplot2::theme_set(ggplot2::theme_minimal()) # Tema dos gráficos produzidos no ggplot2
knitr::opts_chunk$set(echo = F, message = F, warning = F, fig.pos = "H", fig.align = "center", fig.width = 7.8, fig.height = 3.7)
# devtools::install_github("https://github.com/AlissonRP/mypdf1") remova o `#`

library(tidyverse)
library(tidymodels)
library(modeltime)
library(forecast)
#library(workflowsets)
#library(sknifedatar)
```

```{r functions}
barplot <- function(df, v) {
  ggplot(df, aes(
    x = {{ v }},
    y = prop.table(stat(count)),
    fill = {{ v }},
    label = scales::percent(prop.table(stat(count)))
  )) +
    geom_bar(position = "dodge", color = "black") +
    geom_text(
      stat = "count",
      position = position_dodge(.9),
      vjust = -0.5,
      size = 3.5
    ) +
    scale_y_continuous(labels = scales::percent) +
    labs(y = "Proporção", x = df %>%
      select({{ v }}) %>%
      names(), caption = "Fonte: Elaborado pelos autores") +
    theme(plot.title = element_text(hjust = 0.5, size = 10), legend.position = "none")
}

scale_fill_alisson <- function(...) {
  ggplot2:::manual_scale(
    "fill",
    values = setNames(
      c("#EA2129", "#CF6520", "#1EAB78"), levels(as.factor(df$Tipo)),
      ...
    )
  )
}

calcSSE <- function(data, regressor, time, x) {
  loessMod <- try(loess(eval(parse(text = paste(regressor, "~", paste("as.numeric(", time, ")", sep = ""), sep = " "))), data = data, span = x), silent = T)
  res <- try(loessMod$residuals, silent = T)
  if (class(res) != "try-error") {
    sse <- sum(res^2)
  } else {
    sse <- 99999
  }
  return(sse)
}

my_metrics <- default_forecast_accuracy_metric_set()

scale_fill_discrete <- \(...) scale_fill_alisson(...)
```

# Introdução
Naruto é uma animação japonesa (anime)  que adapta a  série de mangá escrita e ilustrada por Masashi Kishimoto, que conta a história de Naruto Uzumaki, um jovem ninja que constantemente procura por reconhecimento e sonha em se tornar Hokage, o ninja líder de sua vila.  
A história é dividida em duas partes, a primeira parte se passa nos anos da pré-adolescência de Naruto (clássico), e a segunda parte se passa em sua adolescência (Shippuden). Nesse trabalho trataremos sobre o Naruto Shippuden, desenvolvendo-o em uma perpestiva de séries temporais, vamos adotar como variável de interesse  a avaliação dos episódios, assim veremos  pontos importantes da saga ao longo do tempo.   
O Banco de dados utilizado é totalmente original, foi criado fazendo *Web scraping* de dois sites diferentes, para aqueles interessados o banco foi dispobilizado [aqui](https://www.kaggle.com/alisson987/naruto-shippuden-rate).


# Informações
```{r }
df <- read_csv("naruto.csv")
```
Como o anime é uma adaptação, existem  episódios fiéis ao mangá (Manga Canon) e episódios  originais do próprio anime, em outras palavras não seguem o material original, esses episódios são chamados de Fillers, existem também episódios que seguem a trama do mangá mas além disso possuem elementos novos, esses chamados de Mixed Canon.  
Vejamos pelo gráfico a seguir a porcentagem do tipo dos episódios

```{r plttipo}
barplot(df, Tipo)
```
É um fato bastante curioso, Naruto Shippuden possui uma quantidade altíssima de episódios fillers, aproximadamente 41%, note pela tabela  que são somente 31 episódios a mais canônicos.
```{r}
df %>%
  group_by(Tipo) %>%
  count() %>%
  rename(Quantidade = n) %>%
  mypdf1::pdf1_tbl("Valores Absolutos do Tipo de Episódio")
```

Em termos de avaliação ao longo do tempo, podemos utilizar como indíce ordinal o próprio número do episódio já que que é uma função injetora no tempo.

```{r}
df %>%
  ggplot(aes(x = numero_episodio, y = rate)) +
  geom_line() +
  gghighlight::gghighlight(200 < numero_episodio & numero_episodio < 400,
    unhighlighted_params = list(colour = "#CB6007")
  ) +
  labs(x = "Numero do episódio", y = "Avaliação")
```
Há bastante coisa a se notar nesse gráfico, primeiramente pelos episódios 200 e 400, existe um indício de alteração na média das variáveis aleatórias, portanto furando o pressuposto de média constante ao longo do tempo, perto dos episódios finais da saga nota-se  também inúmeras quedas bruscas na avaliação sem um contra-peso de avaliações com notas altas, outro indicio de não estacionariedade.  
É importante tentarmos entender um pouco sobre esses episódios com notas baixas, assim vamos ver esse gráfico pelo tipo de episódio.

```{r}
df %>%
  ggplot(aes(x = numero_episodio, y = rate, color = Tipo, group = 1)) +
  geom_line() +
  labs(x = "Numero do episódio", y = "Avaliação") +
  ggplot2::scale_color_manual(breaks = c(levels(as.factor(df$Tipo))), values = c("#EA2129", "#E08223", "#1CD0AD"))
```
Assim fica fácil ver que os episódios com menor avaliação são em sua maior parte fillers, toda queda brusca de avaliação tem um episódio filler envolvido.

É necessário também avaliar a correlação nas avaliações:
```{r}
## esse pacote aqui tem problemas, forecast::ggAcf(df$rate) não funciona, sou obrigado a dar library

ggAcf(df$rate, lag.max = 35, type = c("correlation")) +
  labs(title = "Função de autocorrelação")
```
Uma abordagem importante também é decompor a série temporal, apriori supõe-se a existência de três elementos, a saber: Tendência, sazonalidade e resíduo. Todos esses serão explorados cuidadosamente nas seções posteriores, assim vamos decompor a série para ter um vislumbre de tais elementos:

```{r}
decompose <- forecast::mstl(df$rate)
decompose |> autoplot()
```
A questão de curiosidade vamos ver se os resíduos seguem uma distribuição normal, para isso utilizamos o teste de Shapiro Wilk que possui como hipótese:
$$
H_0:\text{Os dados seguem uma distribuição Normal}
$$
```{r}
# normal K
norm=data.frame(decompose)$Remainder |>
  shapiro.test() |> 
  (\(x) x$p.value)()
```
Efetuando o teste obtemos um p-valor de `r norm`, assim portando rejeitando a hipótese $H_0$, porém os resíduos não possuirem distribuição normal não afetará as analises daqui pra frente.


# Testes
Os gráficos de seção anterior evidenciaram a possibilidade da série não ser estacionária, assim faz-se necessário verificar se  vale de fato para o processo estocástico, com isso  vamos precisar aplicar testes de hipóteses para averiguar  algumas propriedades, como existência de tendência e  sazonalidade.

### Tendência 

Tendência refere-se a um algum  comportamento   não - estocástico da série em algum momento do tempo, se tal comportamento só acontece em alguns momentos especifícos do tempo, chamamos de tendência estocástica, do contrário é dita determinística. Vamos começar pelos testes de tendência determinística, que em termos sumarizados possuem como hipótese:
$$
H_0:\text{A série não possui tendência determinística}
$$
```{r}
kendal <- trend::mk.test(df$rate)
wald <- trend::ww.test(df$rate)
stuart <- trend::cs.test(df$rate)
tab1 <- as.data.frame(c("Cox-Stuart", "Wald-Wolfowitz", "Mann-Kendall"))
tab1[, 2] <- c(stuart$p.value, wald$p.value, kendal$p.value)
names(tab1) <- c("Testes", "P-valor")

#Sim eu removi os `**` grrr
```

```{r}
tab1 %>%
  mypdf1::pdf1_tbl("Testes de Tendência Determinística")
```

Conforme mostrado pela Tabela anterior podemos ver que pelos testes de 
Cox-Stuart, Wald-Wolfowitz, Mann-Kendall, temos que todos os p-valores são menores pequenos, então concluímos que existe tendência determinística na série temporal. 


### Sazonalidade
Sazonalidade acontece quando a série possui um comportamento que se repete frequencialmente, vamos nessa subseção testar se existe sazonalidade nas avaliação dos episódios, assim temos como hipótese:
$$
H_0:\text{A série não possui sazonalidade}
$$
Os testes aplicados  foram 
Kruskal-Wallis, Friedman e Autocorrelação em lags Sazonais, assim gerando a seguite tabela:

```{r}
krusk <- seastests::kw(df$rate, freq = 7)
friedman <- seastests::fried(df$rate, freq = 7)
tqs <- seastests::qs(df$rate, freq = 7)
tab2 <- as.data.frame(c("Kruskal-Wallis", "Friedman", "Autocorrelação em lags Sazonais"))
tab2[, 2] <- c(krusk$Pval, friedman$Pval, tqs$Pval)
names(tab2) <- c("Testes", "P-valor")
tab2$`P-valor` <- round(tab2$`P-valor`, 4)
tab2$`P-valor` <- ifelse(tab2$`P-valor` < 0.05, ifelse(tab2$`P-valor` < 0.0001, "<0,0001*", paste0(as.character(tab2$`P-valor`), "*")), tab2$`P-valor`)
```

```{r}
tab2 %>%
  mypdf1::pdf1_tbl("Testes de Sazonalidade")
```

Assim como os testes obtiveram p-valor$>$0.5, concluímos portanto que não existem indícios de sazonalidade. 

### Testes de Raiz unitária
Para começar tal seção, primeiros vamos definir um passeio aleatório em sua forma simplificada:
$$
Y_t=Y_{t-1}+\epsilon_t
$$
Onde t refere-se aos indíces de ordenação, e $\epsilon$  um termo aleatório, para facilidade vamos assumir que $E(\epsilon_t)=\mu$ e $var(\epsilon_t)=\sigma^2$ $\forall t$, assim subtraindo-se $Y_{t-1}$ em ambos os lados tem-se $$Y_t-Y_{t-1}=\epsilon_t$$ que é um processo estacionário, o processo anterior é dito processo estacionário em diferença, em outros casos também chamado de processo integrado. O exemplo anterior trata-se de um caso mais geral $$Y_t=\phi Y_{t-1}+\epsilon_t$$ onde evidentemente $\phi=1$, é fácil mostrar que se $|\phi|<1$ tem-se um processo estocástico, aqui portanto, estamos interessados nesse caso, para isso utilizaremos  testes de hipótese. 

Fala-se também que o caso anterior na forma simplificada possui raiz unitária, por causa do operador Lag, aqui não definido, porém  pode-se ler sobre em @morettin2018analise

```{r}
kpss <- tseries::kpss.test(df$rate, null = c("Level", "Trend"), lshort = TRUE)
adf <- tseries::adf.test(df$rate)
pp <- tseries::pp.test(df$rate)
tab3 <- as.data.frame(c("Kwiatkowski-Phillips-Schmidt-Shin (KPSS)", "Augmented Dickey-Fuller (ADF)", "Phillips-Perron (PP)"))
tab3[, 2] <- c(kpss$p.value, adf$p.value, pp$p.value)
names(tab3) <- c("Testes", "P-valor")
tab3$`P-valor` <- round(tab3$`P-valor`, 4)
tab3$`P-valor` <- ifelse(tab3$`P-valor` < 0.05, ifelse(tab3$`P-valor` < 0.0001, "<0,0001*", paste0(as.character(tab3$`P-valor`), "*")), tab3$`P-valor`)
```

```{r}
tab3 %>%
  mypdf1::pdf1_tbl("Testes de Tendência Estocástica")
```

Conforme mostrado pela Tabela anterior podemos ver que pelos testes de 
Dickey-Fuller Aumentado, Phillips-Perron, KPSS, com índice de significância de 5%, temos que os p-valores dos testes ADF e PP são menores que 0.05 e do teste KPSS é maior que 0.05, então concluímos que não existe tendência estocástica na série temporal. Pois, nos testes ADF e PP, a hipótese nula é a existência de raiz unitária e no teste de KPSS, a hipótese nula é não existência de raiz unitária.


# Modelagem

```{r }
t <- df %>%
  ggplot(aes(numero_episodio, rate)) +
  geom_line(size = 0.8, color = "#050A03") +
  theme_void() +
  labs("Série")
t %>%
  ggimage::ggbackground(background = "https://www.ixpap.com/images/2021/03/desktop-naruto-wallpaper-ixpap.jpg")
```


```{r }
df %>%
  group_by(Saga) %>%
  summarise(mean = mean(rate)) %>%
  arrange(desc(mean))
```

## Médias Móveis Simples


```{r}
mms <- TTR::SMA(df$rate, n = 10)

mms <- TTR::SMA(df$rate, n = 21)

df1 <- cbind(df, mms)
```


```{r}
df1 %>%
  ggplot(aes(x = numero_episodio)) +
  geom_line(aes(y = rate, colour = "SerieNormal")) +
  geom_line(aes(y = mms, colour = "MediaMovel")) +
  labs(x = "Numero do episódio", y = "Avaliação") +
  scale_colour_manual("",
    breaks = c("SerieNormal", "MediaMovel"),
    values = c(
      "SerieNormal" = "#1EAB78",
      "MediaMovel" = "#CF6520"
    )
  )
```

### Previsão
Utilizando o pacote smooth.

```{r, results = F, fig.show='hide'}
mms1 <- smooth::sma(df$rate[1:400], order=21,silent=FALSE, interval= 'p', h=100)
fit_forecast<- data.frame(forecast= c(mms1$fitted,mms1$forecast), n = 1:length(c(mms1$fitted,mms1$forecast)))
fit_forecast<- fit_forecast %>%
  mutate(Dados = case_when(
    n == 1:length(mms1$fitted) ~ "Predição",
    n == (length(mms1$fitted)+1):length(c(mms1$fitted,mms1$forecast)) ~ "Previsão"))
ICbands <- data.frame(upper=mms1$upper, lower=mms1$lower, n=(length(mms1$fitted)+1):(length(mms1$fitted) +length(mms1$forecast)))
```


```{r}
ggplot()+
   geom_ribbon(data=ICbands, aes(x=n,ymin=lower, ymax=upper), fill = 'grey70')+
   geom_line(data = df1, aes(x= numero_episodio,y = rate, colour = "SerieNormal"))+
   geom_line(data=fit_forecast,aes(x=n,y = forecast, colour = "Forecast"))+
   geom_vline(xintercept=max(df1$numero_episodio))

```

```{r}
ggplot()+
   geom_ribbon(data=ICbands, aes(x=n,ymin=lower, ymax=upper), fill = 'grey70')+
   geom_line(data = df1, aes(x= numero_episodio,y = rate, colour = "SerieNormal"))+
   geom_line(data=fit_forecast,aes(x=n,y = forecast, colour = "Forecast"))+
   geom_vline(xintercept=max(df1$numero_episodio))
```

## Regressão LOESS

```{r, results = F}
op1 <- optim(par = c(0.5), fn = calcSSE, method = "SANN", data = df1, regressor = "rate", time = "Time")
rl1 <- loess(rate ~ as.numeric(Time), data = df1, span = op1$par)
predict(rl1,seq(as.Date("2017-03-23"), length = 5, by = 'week'))
prl <- predict(rl1, as.numeric(df1$Time), se = T)
df1 <- cbind(df, prl$fit) #Página 78, linha 45 à 52.
```


```{r}
df1 %>%
  ggplot(aes(x = numero_episodio)) +
  geom_line(aes(y = rate, colour = "SerieNormal")) +
  geom_line(aes(y = `prl$fit`, colour = "RegLoess")) +
  geom_ribbon(aes(ymin=prl$fit-prl$se.fit, ymax=prl$fit+prl$se.fit, alpha = 0.05)) +
  labs(x = "Numero do episódio", y = "Avaliação") +
  scale_colour_manual("",
    breaks = c("SerieNormal", "RegLoess"),
    values = c(
      "SerieNormal" = "#1EAB78",
      "RegLoess" = "#CF6520"
    )
  )
```

## Suavização Exponencial
### Com pacote ModelTime
Estamos usando a avaliação dos episódios do anime como variável dependente de duas formas: Na forma original e aplicando logaritmo. Usaremos também 6 modelos: ETS (M, M, M), ETS(M,A,M), Croston, Theta, Smooth_es(A,A,A) e Smooth_es(A,A,M).

```{r}
splits <- initial_time_split(df, prop=0.8)
df_train=training(splits)
df_test=testing(splits)



```


```{r, results = F,eval = FALSE}

f1 <- rate ~ as.Date(Time)
f2 <- log(rate) ~ as.Date(Time)

model1 <- exp_smoothing(error = "multiplicative",trend = "multiplicative",season = "multiplicative") %>%
    set_engine("ets")
model2 <- exp_smoothing(error = "multiplicative",trend = "additive",season = "multiplicative")  %>%
    set_engine("ets")
model3 <- exp_smoothing() %>%
    set_engine("croston")
model4 <-  exp_smoothing() %>%
    set_engine("theta")
model5 <-exp_smoothing(
  error = "additive",
  trend = "additive",
  season = "multiplicative"
) %>%
    set_engine("smooth_es")
model6 <- exp_smoothing(
  error = "additive",
  trend = "additive",
  season = "additive"
) %>%
  set_engine("smooth_es")

fit1 <- model1 %>% fit(f1, data = df_train)
fit2 <- model1 %>% fit(f2, data = df_train)
fit3 <- model2 %>% fit(f1, data = df_train)
fit4 <- model2 %>% fit(f2, data = df_train)
fit5 <- model3 %>% fit(f1, data = df_train)
fit6 <- model3 %>% fit(f2, data = df_train)
fit7 <- model4 %>% fit(f1, data = df_train)
fit8 <- model4 %>% fit(f2, data = df_train)
fit9 <- model5 %>% fit(f1, data = df_train)
fit10 <- model5 %>% fit(f2, data = df_train)
fit11 <- model5 %>% fit(f1, data = df_train)
fit12 <- model5 %>% fit(f2, data = df_train)


#model_work <- workflow_set(list(log=df_rec1,log=df_rec1,log=df_rec1,rate=df_rec2, rate=df_rec2,rate=df_rec2),
                           #list(mod1=model1,mod2=model2, mod3 =model3,mod1=model1,mod2=model2, mod3 =model3))
#model_work %>% fit()

#ft1=model_work %>% 
#  fit_resamples(df_vf,metrics=metric_set(accuracy,roc_auc,sensitivity,specificity),
#                control = control_resamples(save_pred = TRUE)) %>% 
#  collect_predictions()
models1 <- modeltime_table(fit1,fit3,fit5,fit7,fit9, fit11)
models2 <- modeltime_table(fit2,fit4,fit6,fit8,fit10, fit12)

predict_models1 <- models1 %>%
    modeltime_calibrate(new_data = df_test)
predict_models2 <- models2 %>%
    modeltime_calibrate(new_data = df_test)
```

#### Gráficos
```{r,eval = FALSE}
p <- predict_models1 %>%
    modeltime_forecast(
        new_data    = df_test,
        actual_data = df
    ) %>%
    plot_modeltime_forecast(
    )
```
```{r}
p
```


```{r,eval = FALSE}
p1  <- predict_models2 %>%
    modeltime_forecast(
        new_data    = df_test,
        actual_data = df
    ) %>%
    plot_modeltime_forecast(
    )
```

```{r,eval = FALSE}
p1
```


#### Tabelas das Métricas

```{r,eval = FALSE}
t1 <- predict_models1 %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy()
```


```{r}
t1
```


```{r}
t2 <- predict_models2 %>%
    modeltime_accuracy() %>%
  table_modeltime_accuracy()
```


```{r}
t2
```

### Com outros pacotes

```{r}
dfts = msts(df %>% select(rate, numero_episodio),seasonal.periods = 365/7, start=c(2007,2.5))
treino <- df[1:400,]
treino <- window(dfts[,1], end=c(2014,38))
teste <- window(dfts[,1], start=c(2014,38))

h1 <- holt(treino, h = 100)
h2 <- holt(treino, damped=TRUE, h = 100)

HoltWinters(treino,seasonal="multiplicative") #Não consegui utilizar voltou o erro de frequência
h1$model$
```
#### Holt não Amortecido

```{r}
forecast_h1 <- data.frame(forecast= c(h1$fitted,h1$mean), n = 1:length(c(h1$fitted,h1$mean)))
ICbands_h1 <- data.frame(upper=h1$upper[,2], lower=h1$lower[,2], n=(length(h1$fitted)+1):(length(h1$fitted) +length(h1$mean)))
forecast_h1<- forecast_h1 %>%
  mutate(Dados = case_when(
    n == 1:length(h1$fitted) ~ "Predição",
    n == (length(h1$fitted)+1):length(c(h1$fitted,h1$mean)) ~ "Previsão"))
ggplot() + 
  geom_ribbon(data=ICbands_h1, aes(x=n,ymin=lower, ymax=upper), fill = 'grey70') + 
  geom_line(data = df1, aes(x= numero_episodio,y = rate, colour = "SerieNormal")) + 
  geom_line(data=forecast_h1,aes(x=n,y = forecast, colour = "Forecast")) +
  geom_vline(xintercept=max(df1$numero_episodio))
```


#### Holt com Amortecimento

```{r}
forecast_h2 <- data.frame(forecast= c(h2$fitted,h2$mean), n = 1:length(c(h2$fitted,h2$mean)))
ICbands_h2 <- data.frame(upper=h2$upper[,2], lower=h2$lower[,2], n=(length(h2$fitted)+1):(length(h2$fitted) +length(h2$mean)))
forecast_h2<- forecast_h2 %>%
  mutate(Dados = case_when(
    n == 1:length(h2$fitted) ~ "Predição",
    n == (length(h2$fitted)+1):length(c(h2$fitted,h2$mean)) ~ "Previsão"))
ggplot() + 
  geom_ribbon(data=ICbands_h2, aes(x=n,ymin=lower, ymax=upper), fill = 'grey70') + 
  geom_line(data = df1, aes(x= numero_episodio,y = rate, colour = "SerieNormal")) + 
  geom_line(data=forecast_h2,aes(x=n,y = forecast, colour = "Forecast")) +
  geom_vline(xintercept=max(df1$numero_episodio))
```

## Outros modelos do pacote ModelTime
```{r}
model7 <- prophet_reg() %>% set_engine("prophet")
model8 <-  prophet_boost(
    learn_rate = 0.1
) %>%
    set_engine("prophet_xgboost")
model9 <- arima_reg() %>%
    set_engine("auto_arima")
model10 <- arima_boost(
    tree_depth = 6,
    learn_rate = 0.1
) %>%
    set_engine(engine = "arima_xgboost")
model11 <-  nnetar_reg() %>%
    set_engine("nnetar")
fit13 <- model7 %>% fit(f1, data = df_train)
fit14 <- model7 %>% fit(f2, data = df_train)
fit15 <- model8 %>% fit(f1, data = df_train)
fit16 <- model8 %>% fit(f2, data = df_train)
fit17 <- model9 %>% fit(f1, data = df_train)
fit18 <- model9 %>% fit(f2, data = df_train)
fit19 <- model10 %>% fit(f1, data = df_train)
fit20 <- model10 %>% fit(f2, data = df_train)
fit21 <- model11 %>% fit(f1, data = df_train)
fit22 <- model11 %>% fit(f2, data = df_train)
models3 <- modeltime_table(fit13,fit15,fit17,fit19, fit21)
models4 <- modeltime_table(fit14,fit16,fit18,fit20, fit22)
predict_models1 <- models3 %>%
    modeltime_calibrate(new_data = df_test)
predict_models2 <- models4 %>%
    modeltime_calibrate(new_data = df_test)
predict_models1 %>%
    modeltime_forecast(
        new_data    = df_test,
        actual_data = df
    ) %>%
    plot_modeltime_forecast(
    )
predict_models2 %>%
    modeltime_forecast(
        new_data    = df_test,
        actual_data = df
    ) %>%
    plot_modeltime_forecast(
    )
predict_models1 %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy()
t3<- predict_models2 %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy()
metrics <- data.frame(NULL)

for(i in 1:5){
  if(i == 1){
    metrics <- my_metrics(df,predict_models1[[5]][[i]]$.actual ,predict_models1[[5]][[i]]$.prediction)
  } else{
  metrics <- cbind(metrics, my_metrics(df,predict_models1[[5]][[i]]$.actual ,predict_models1[[5]][[i]]$.prediction))
  }
}
names(metrics) <- c(".metric1", ".estimator1", ".estimate1",".metric2",".estimator2",".estimate2",".metric3",    ".estimator3", ".estimate3", ".metric4", ".estimator4", ".estimate4", ".metric5",".estimator5", ".estimate5")
metrics <-  metrics %>%
  select(-c(2,4:5,7:8,10:11,13:14))
names(metrics) <- c("Métricas", "Prophet", "Prophet Boost", "Auto Arima", "Auto Arima Boost", "NNetar")
Metricas <- unlist(metrics %>% select(Métricas))
metrics <- metrics %>% select(-Métricas) %>% t() %>% as.data.frame()
names(metrics) <- str_to_upper(Metricas)
```



## Calculando Métricas de Acurácia dos Modelos não-ModelTime

```{r}
true_values1 = df %>% filter(numero_episodio > max(numero_episodio) - nrow(fit_forecast %>% filter(Dados == "Previsão"))) %>% select(rate)
true_values2 = df %>% filter(numero_episodio > max(numero_episodio - nrow(forecast_h2 %>% filter(Dados == "Previsão")))) %>% select(rate)
v1 = fit_forecast %>% filter(Dados == "Previsão") %>% select(forecast)
v2 = forecast_h1 %>% filter(Dados == "Previsão") %>% select(forecast)
v3 = forecast_h2 %>% filter(Dados == "Previsão") %>% select(forecast)
dmetrics <- cbind(v1,v2,v3,true_values1,true_values2)
names(dmetrics) <- c("v1","v2","v3","true_values1","true_values2")
m1 <- my_metrics(dmetrics, true_values1, v1)
m2 <- my_metrics(dmetrics, true_values2, v2)
m3 <- my_metrics(dmetrics, true_values2, v3)
inner_join(m1,m2, by = '.metric') %>%
inner_join(m3, by = '.metric') -> M1
M1 <- M1 %>% select(-c(.estimator.x, .estimator.y, .estimator)) 
names(M1) <- c("Métricas", "SMA", "Holt", "Holt amortecido")
Metricas <- unlist(M1 %>% select(Métricas))
M1 <- M1 %>% select(-Métricas) %>% t() %>% as.data.frame()
names(M1) <- str_to_upper(Metricas)

```

```{r}
M1 %>%
    mypdf1::pdf1_tbl("Métricas nos dados de teste")
```


# Referências
